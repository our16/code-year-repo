{
  "project": {
    "path": "F:\\project\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI",
    "name": "ComfyUI",
    "auto_discovered": true
  },
  "data": {
    "project_name": "ComfyUI",
    "path": "F:\\project\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI",
    "commits": [
      {
        "hash": "f16219e3aadcb7a301a1a313ab8989c3ebe53764",
        "short_hash": "f16219e3",
        "date": "2025-11-26T17:00:43",
        "timestamp": 1764147643,
        "message": "Add cheap latent preview for flux 2. (#10907)\n\nThank you to the person who calculated them. You saved me a percent of my\ntime.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 2,
        "additions": 45,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "8402c8700a29a97bc5d706d6a0b14c41bc2c2d8a",
        "short_hash": "8402c870",
        "date": "2025-11-26T15:41:13",
        "timestamp": 1764142873,
        "message": "ComfyUI version v0.3.75",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "58b85746618e2bc2dd32024c89403926aad59f48",
        "short_hash": "58b85746",
        "date": "2025-11-26T15:36:19",
        "timestamp": 1764142579,
        "message": "Fix Flux2 reference image mem estimation. (#10905)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "90b3995ec842335e44d70e0521ff6ff6c3ff9aaa",
        "short_hash": "90b3995e",
        "date": "2025-11-26T13:34:15",
        "timestamp": 1764135255,
        "message": "ComfyUI v0.3.74",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "bdb10a583f1b1e495ee00dbd1674f11016a6a93e",
        "short_hash": "bdb10a58",
        "date": "2025-11-26T13:07:58",
        "timestamp": 1764133678,
        "message": "Fix loras not working on mixed fp8. (#10899)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 4,
        "additions": 37,
        "deletions": 9,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "0e24dbb19f34f242edb77c550396cf6806f7b22f",
        "short_hash": "0e24dbb1",
        "date": "2025-11-26T08:02:51",
        "timestamp": 1764115371,
        "message": "Adjustments to Z Image. (#10893)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 21,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e9aae31fa241a6a63a368800146ea91629d4e8c2",
        "short_hash": "e9aae31f",
        "date": "2025-11-26T07:41:45",
        "timestamp": 1764114105,
        "message": "Z Image model. (#10892)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 7,
        "additions": 199,
        "deletions": 152,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "0c18842acbdf546883b08808dd9feea7605d7649",
        "short_hash": "0c18842a",
        "date": "2025-11-26T03:59:37",
        "timestamp": 1764100777,
        "message": "ComfyUI v0.3.73",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "d196a905bb379a6d800d0c13f9b4fdea3965311a",
        "short_hash": "d196a905",
        "date": "2025-11-26T03:58:39",
        "timestamp": 1764100719,
        "message": "Lower vram usage for flux 2 text encoder. (#10887)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 3,
        "additions": 15,
        "deletions": 8,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "18b79acba95d44b4ea00bbbfc1856bc71bd58841",
        "short_hash": "18b79acb",
        "date": "2025-11-26T03:58:21",
        "timestamp": 1764100701,
        "message": "Update workflow templates to v0.7.20 (#10883)",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "dff996ca39d86265bbabf15e666484e051f0b3d5",
        "short_hash": "dff996ca",
        "date": "2025-11-26T03:30:24",
        "timestamp": 1764099024,
        "message": "Fix crash. (#10885)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "828b1b9953175b6df79459f417d1032869d0b46a",
        "short_hash": "828b1b99",
        "date": "2025-11-26T01:40:58",
        "timestamp": 1764092458,
        "message": "ComfyUI version v0.3.72",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "af81cb962d9dd283ddb551962cc223b5a186a1ce",
        "short_hash": "af81cb96",
        "date": "2025-11-26T00:40:32",
        "timestamp": 1764088832,
        "message": "Add Flux 2 support to README. (#10882)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "5c7b08ca58f5412b3a814b374793cacdb5b5f0a7",
        "short_hash": "5c7b08ca",
        "date": "2025-11-26T00:09:07",
        "timestamp": 1764086947,
        "message": "[API Nodes] add Flux.2 Pro node (#10880)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 3,
        "additions": 143,
        "deletions": 125,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6b573ae0cb11000a0330a35d9e31917c22c874a4",
        "short_hash": "6b573ae0",
        "date": "2025-11-25T23:50:19",
        "timestamp": 1764085819,
        "message": "Flux 2 (#10879)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 12,
        "additions": 506,
        "deletions": 68,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "015a0599d08f1072155b9213d488b73e502fea3c",
        "short_hash": "015a0599",
        "date": "2025-11-25T16:23:19",
        "timestamp": 1764058999,
        "message": "I found a case where this is needed (#10875)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "acfaa5c4a132e1c01bc9d94e76b0d667c899bfd1",
        "short_hash": "acfaa5c4",
        "date": "2025-11-25T15:55:49",
        "timestamp": 1764057349,
        "message": "Don't try fp8 matrix mult in quantized ops if not supported by hardware. (#10874)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b6805429b9c2f3aa919035bea849ecd1de3ac8e4",
        "short_hash": "b6805429",
        "date": "2025-11-25T15:48:20",
        "timestamp": 1764056900,
        "message": "Allow pinning quantized tensors. (#10873)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 2,
        "additions": 13,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "25022e0b0965975b35bcaf28b153184d60a4f9de",
        "short_hash": "25022e0b",
        "date": "2025-11-25T14:48:53",
        "timestamp": 1764053333,
        "message": "Cleanup and fix issues with text encoder quants. (#10872)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 7,
        "additions": 138,
        "deletions": 112,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "22a2644e57530ee40e13486ccd7c953b87072093",
        "short_hash": "22a2644e",
        "date": "2025-11-25T08:45:54",
        "timestamp": 1764031554,
        "message": "Bump transformers version in requirements.txt (#10869)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b2ef58e2b17e73ca8cd376a1cdc976518ebbc168",
        "short_hash": "b2ef58e2",
        "date": "2025-11-25T02:40:09",
        "timestamp": 1764009609,
        "message": "block info (#10844)",
        "author": "Haoming",
        "email": "73768377+Haoming02@users.noreply.github.com",
        "files_changed": 1,
        "additions": 6,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6a6d456c88723538e3d0e5e942f78109ece5b73d",
        "short_hash": "6a6d456c",
        "date": "2025-11-25T02:38:38",
        "timestamp": 1764009518,
        "message": "block info (#10842)",
        "author": "Haoming",
        "email": "73768377+Haoming02@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "3d1fdaf9f448b34e4eba68bfd8e8de373ec0d22d",
        "short_hash": "3d1fdaf9",
        "date": "2025-11-25T02:30:40",
        "timestamp": 1764009040,
        "message": "block info (#10843)",
        "author": "Haoming",
        "email": "73768377+Haoming02@users.noreply.github.com",
        "files_changed": 1,
        "additions": 6,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "1286fcfe40b98052e4edbe9a02f12ad89ac74924",
        "short_hash": "1286fcfe",
        "date": "2025-11-25T02:24:29",
        "timestamp": 1764008669,
        "message": "add get_frame_count and get_frame_rate methods to VideoInput class (#10851)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 3,
        "additions": 105,
        "deletions": 8,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "3bd71554a2df14b862cc5e1e875df37ba24af1ac",
        "short_hash": "3bd71554",
        "date": "2025-11-25T01:48:37",
        "timestamp": 1764006517,
        "message": "fix(api-nodes): edge cases in responses for Gemini models (#10860)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 2,
        "additions": 14,
        "deletions": 13,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f66183a54142be693ab858e9f1f06ed62439a92e",
        "short_hash": "f66183a5",
        "date": "2025-11-24T14:56:20",
        "timestamp": 1763967380,
        "message": "[fix] Fixes non-async public API access (#10857)\n\nIt looks like the synchronous version of the public API broke due to an\naddition of `from __future__ import annotations`. This change updates\nthe async-to-sync adapter to work with both types of type annotations.",
        "author": "guill",
        "email": "jacob.e.segal@gmail.com",
        "files_changed": 2,
        "additions": 184,
        "deletions": 16,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "cbd68e3d587a1b345bdc6ebcd8a8c6ba1a9d3af3",
        "short_hash": "cbd68e3d",
        "date": "2025-11-23T17:55:22",
        "timestamp": 1763891722,
        "message": "Add better error message for common error. (#10846)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "d89c29f25992713ec3102017c189858a457f1215",
        "short_hash": "d89c29f2",
        "date": "2025-11-23T11:51:53",
        "timestamp": 1763869913,
        "message": "Add display names to Hunyuan latent video nodes. (#10837)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "a9c35256bccd4018fbe74bf1e857cc18bd1900ed",
        "short_hash": "a9c35256",
        "date": "2025-11-22T18:28:29",
        "timestamp": 1763807309,
        "message": "Update requirements.txt (#10834)",
        "author": "Christian Byrne",
        "email": "cbyrne@comfy.org",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "532938b16b544e4492ba0ffbe18b201b1a7bc55f",
        "short_hash": "532938b1",
        "date": "2025-11-22T06:51:55",
        "timestamp": 1763765515,
        "message": "--disable-api-nodes now sets CSP header to force frontend offline. (#10829)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 2,
        "additions": 20,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "ecb683b057a19f1a05d18d6d0b0ee9a6c6c8f4a0",
        "short_hash": "ecb683b0",
        "date": "2025-11-22T05:34:47",
        "timestamp": 1763760887,
        "message": "update frontend to 1.30 (#10793)",
        "author": "Christian Byrne",
        "email": "cbyrne@comfy.org",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "c55fd7481626d8bee8044ea7512ea996d13a1b90",
        "short_hash": "c55fd748",
        "date": "2025-11-21T13:49:13",
        "timestamp": 1763704153,
        "message": "ComfyUI 0.3.71",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "33981237527a3d84d4e9c3b113f75d6dd37af6a4",
        "short_hash": "33981237",
        "date": "2025-11-21T12:39:37",
        "timestamp": 1763699977,
        "message": "Fix wrong path. (#10821)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "943b3b615d40542ea19bc8ff8ad2950c0a094605",
        "short_hash": "943b3b61",
        "date": "2025-11-21T11:44:43",
        "timestamp": 1763696683,
        "message": "HunyuanVideo 1.5 (#10819)\n\n* init\n\n* update\n\n* Update model.py\n\n* Update model.py\n\n* remove print\n\n* Fix text encoding\n\n* Prevent empty negative prompt\n\nReally doesn't work otherwise\n\n* fp16 works\n\n* I2V\n\n* Update model_base.py\n\n* Update nodes_hunyuan.py\n\n* Better latent rgb factors\n\n* Use the correct sigclip output...\n\n* Support HunyuanVideo1.5 SR model\n\n* whitespaces...\n\n* Proper latent channel count\n\n* SR model fixes\n\nThis also still needs timesteps scheduling based on the noise scale, can be used with two samplers too already\n\n* vae_refiner: roll the convolution through temporal\n\nWork in progress.\n\nRoll the convolution through time using 2-latent-frame chunks and a\nFIFO queue for the convolution seams.\n\n* Support HunyuanVideo15 latent resampler\n\n* fix\n\n* Some cleanup\n\nCo-Authored-By: comfyanonymous <121283862+comfyanonymous@users.noreply.github.com>\n\n* Proper hyvid15 I2V channels\n\nCo-Authored-By: comfyanonymous <121283862+comfyanonymous@users.noreply.github.com>\n\n* Fix TokenRefiner for fp16\n\nOtherwise x.sum has infs, just in case only casting if input is fp16, I don't know if necessary.\n\n* Bugfix for the HunyuanVideo15 SR model\n\n* vae_refiner: roll the convolution through temporal II\n\nRoll the convolution through time using 2-latent-frame chunks and a\nFIFO queue for the convolution seams.\n\nAdded support for encoder, lowered to 1 latent frame to save more\nVRAM, made work for Hunyuan Image 3.0 (as code shared).\n\nFixed names, cleaned up code.\n\n* Allow any number of input frames in VAE.\n\n* Better VAE encode mem estimation.\n\n* Lowvram fix.\n\n* Fix hunyuan image 2.1 refiner.\n\n* Fix mistake.\n\n* Name changes.\n\n* Rename.\n\n* Whitespace.\n\n* Fix.\n\n* Fix.\n\n---------\n\nCo-authored-by: kijai <40791699+kijai@users.noreply.github.com>\nCo-authored-by: Rattus <rattus128@gmail.com>",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 15,
        "additions": 779,
        "deletions": 128,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "10e90a5757906ecdb71b84d41173813d7f62c140",
        "short_hash": "10e90a57",
        "date": "2025-11-21T10:20:52",
        "timestamp": 1763691652,
        "message": "bump comfyui-workflow-templates for nano banana 2 (#10818)\n\n* bump templates\n\n* bump templates",
        "author": "Christian Byrne",
        "email": "cbyrne@comfy.org",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b75d349f25ccb702895c6f1b8af7aded63a7f7e2",
        "short_hash": "b75d349f",
        "date": "2025-11-21T08:33:54",
        "timestamp": 1763685234,
        "message": "fix(KlingLipSyncAudioToVideoNode): convert audio to mp3 format (#10811)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "7b8389578e88dcd13b1cf6aea5404047298c9183",
        "short_hash": "7b838957",
        "date": "2025-11-21T08:17:47",
        "timestamp": 1763684267,
        "message": "feat(api-nodes): add Nano Banana Pro (#10814)\n\n* feat(api-nodes): add Nano Banana Pro\n\n* frontend bump to 1.28.9",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 4,
        "additions": 215,
        "deletions": 10,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "9e00ce5b76ec04be37375310512a443605b95077",
        "short_hash": "9e00ce5b",
        "date": "2025-11-21T06:42:46",
        "timestamp": 1763678566,
        "message": "Make Batch Images node add alpha channel when one of the inputs has it (#10816)\n\n* When one Batch Image input has alpha and one does not, add empty alpha channel\n\n* Use torch.nn.functional.pad",
        "author": "Jedrzej Kosinski",
        "email": "kosinkadink1@gmail.com",
        "files_changed": 1,
        "additions": 4,
        "deletions": 3,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f5e66d5e47271253edad5c4eddd817b0d6a23340",
        "short_hash": "f5e66d5e",
        "date": "2025-11-21T04:08:03",
        "timestamp": 1763669283,
        "message": "Fix ImageBatch with different channel count. (#10815)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 4,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "87b0359392219841c2214e1eb06678840cae470e",
        "short_hash": "87b03593",
        "date": "2025-11-20T14:36:56",
        "timestamp": 1763620616,
        "message": "Update server templates handler to use new multi-package distribution (comfyui-workflow-templates versions >=0.3) (#10791)\n\n* update templates for monorepo\n\n* refactor",
        "author": "Christian Byrne",
        "email": "cbyrne@comfy.org",
        "files_changed": 3,
        "additions": 92,
        "deletions": 9,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "cb96d4d18c78ee09d5fd70954ffcb4ad2c7f0d7a",
        "short_hash": "cb96d4d1",
        "date": "2025-11-20T12:56:23",
        "timestamp": 1763614583,
        "message": "Disable workaround on newer cudnn. (#10807)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "394348f5caaa062eac11a57e2997aacccd4246eb",
        "short_hash": "394348f5",
        "date": "2025-11-20T09:44:04",
        "timestamp": 1763603044,
        "message": "feat(api-nodes): add Topaz API nodes (#10755)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 4,
        "additions": 560,
        "deletions": 4,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "7601e89255cde24667d3b4e6022f1385d901748b",
        "short_hash": "7601e892",
        "date": "2025-11-20T09:17:15",
        "timestamp": 1763601435,
        "message": "Fix workflow name. (#10806)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6a1d3a1ae131f3fff7f45a7e835eb10e9d1338ee",
        "short_hash": "6a1d3a1a",
        "date": "2025-11-20T06:49:01",
        "timestamp": 1763592541,
        "message": "convert hunyuan3d.py to V3 schema (#10664)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 5,
        "additions": 178,
        "deletions": 120,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "65ee24c9789b93660ebe978a3186486f105298c2",
        "short_hash": "65ee24c9",
        "date": "2025-11-19T17:25:28",
        "timestamp": 1763544328,
        "message": "change display name of PreviewAny node to \"Preview as Text\" (#10796)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "17027f2a6a20a31e2c6f3be2b1a06f39ad3a68d9",
        "short_hash": "17027f2a",
        "date": "2025-11-19T11:36:03",
        "timestamp": 1763523363,
        "message": "Add a way to disable the final norm in the llama based TE models. (#10794)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 15,
        "deletions": 3,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b5c8be8b1db44ded07cb1b437b9f33ebff5848c1",
        "short_hash": "b5c8be8b",
        "date": "2025-11-19T08:37:20",
        "timestamp": 1763512640,
        "message": "ComfyUI 0.3.70",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "24fdb92edf2e96fe757c480aa7f12be5bdfa3a15",
        "short_hash": "24fdb92e",
        "date": "2025-11-19T06:26:44",
        "timestamp": 1763504804,
        "message": "feat(api-nodes): add new Gemini model (#10789)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 2,
        "additions": 246,
        "deletions": 32,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "d52697457608a045cafc3b6d6cb89f0a49ba0709",
        "short_hash": "d5269745",
        "date": "2025-11-19T05:46:19",
        "timestamp": 1763502379,
        "message": "Fix hunyuan 3d 2.0 (#10792)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e1ab6bb394b82fa654d5bc84043f97479d12f84c",
        "short_hash": "e1ab6bb3",
        "date": "2025-11-18T23:00:21",
        "timestamp": 1763478021,
        "message": "EasyCache: Fix for mismatch in input/output channels with some models (#10788)\n\nSlices model input with output channels so the caching tracks only the noise channels, resolves channel mismatch with models like WanVideo I2V\n\nAlso fix for slicing deprecation in pytorch 2.9",
        "author": "Jukka Sepp√§nen",
        "email": "40791699+kijai@users.noreply.github.com",
        "files_changed": 1,
        "additions": 12,
        "deletions": 10,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "048f49adbd19ac2d9c7c87682c832b7827a4b29d",
        "short_hash": "048f49ad",
        "date": "2025-11-18T19:59:27",
        "timestamp": 1763467167,
        "message": "chore(api-nodes): adjusted PR template; set min python version for pylint to 3.10 (#10787)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 3,
        "additions": 3,
        "deletions": 3,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "47bfd5a33fa984a1102fc2bd7b25c91a69ace288",
        "short_hash": "47bfd5a3",
        "date": "2025-11-18T13:26:44",
        "timestamp": 1763443604,
        "message": "Native block swap custom nodes considered harmful. (#10783)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 2,
        "additions": 40,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "fdf49a28617f742d746ad209e57ed7420b3535dc",
        "short_hash": "fdf49a28",
        "date": "2025-11-18T11:04:06",
        "timestamp": 1763435046,
        "message": "Fix the portable download link for CUDA 12.6 (#10780)",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f41e5f398d5d4059a3c87cf157bd932afcce3c0d",
        "short_hash": "f41e5f39",
        "date": "2025-11-18T08:59:19",
        "timestamp": 1763427559,
        "message": "Update README with new portable download link (#10778)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "27cbac865ec226cfd9c1563327b0d62cf5dbd484",
        "short_hash": "27cbac86",
        "date": "2025-11-18T08:04:04",
        "timestamp": 1763424244,
        "message": "Add release workflow for NVIDIA cu126 (#10777)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 17,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "3d0003c24c1aec9f0c021dbc70ffb7cd8cf0685c",
        "short_hash": "3d0003c2",
        "date": "2025-11-18T06:17:24",
        "timestamp": 1763417844,
        "message": "ComfyUI version 0.3.69",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "7d6103325e1c97aa54f963253e3e7f1d6da6947f",
        "short_hash": "7d610332",
        "date": "2025-11-16T16:01:14",
        "timestamp": 1763280074,
        "message": "Change ROCm nightly install command to 7.1 (#10764)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "2d4a08b717c492fa45e98bd70beb48d4e77cb464",
        "short_hash": "2d4a08b7",
        "date": "2025-11-16T04:37:34",
        "timestamp": 1763239054,
        "message": "Revert \"chore(api-nodes): mark OpenAIDalle2 and OpenAIDalle3 nodes as deprecated (#10757)\" (#10759)\n\nThis reverts commit 9a0238256873711bd38ce0e0b1d15a617a1ee454.",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 0,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "9a0238256873711bd38ce0e0b1d15a617a1ee454",
        "short_hash": "9a023825",
        "date": "2025-11-16T03:18:49",
        "timestamp": 1763234329,
        "message": "chore(api-nodes): mark OpenAIDalle2 and OpenAIDalle3 nodes as deprecated (#10757)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "bd01d9f7fd241a45bd08b60dfedbe78577383cc4",
        "short_hash": "bd01d9f7",
        "date": "2025-11-15T19:54:40",
        "timestamp": 1763207680,
        "message": "Add left padding support to tokenizers. (#10753)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 12,
        "deletions": 5,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "443056c401c53953bb8eee6da71b9ad29afe2581",
        "short_hash": "443056c4",
        "date": "2025-11-14T16:26:05",
        "timestamp": 1763108765,
        "message": "Fix custom nodes import error. (#10747)\n\nThis should fix the import errors but will break if the custom nodes actually try to use the class.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f60923590c3f2fd05e166e2ec57968aaf7007dd0",
        "short_hash": "f6092359",
        "date": "2025-11-14T14:28:05",
        "timestamp": 1763101685,
        "message": "Use same code for chroma and flux blocks so that optimizations are shared. (#10746)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 4,
        "additions": 31,
        "deletions": 135,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "1ef328c007a419c2c429df0f80532cc11579dc97",
        "short_hash": "1ef328c0",
        "date": "2025-11-14T10:32:39",
        "timestamp": 1763087559,
        "message": "Better instructions for the portable. (#10743)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "94c298f9625b0fd9af8ea07a73075fdefe0d9e57",
        "short_hash": "94c298f9",
        "date": "2025-11-14T08:02:03",
        "timestamp": 1763078523,
        "message": "flux: reduce VRAM usage (#10737)\n\nCleanup a bunch of stack tensors on Flux. This take me from B=19 to B=22\nfor 1600x1600 on RTX5090.",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 1,
        "additions": 26,
        "deletions": 7,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "2fde9597f4b02c5f06c1a5ceb3ca2fa6d74966ec",
        "short_hash": "2fde9597",
        "date": "2025-11-14T07:11:52",
        "timestamp": 1763075512,
        "message": "feat: add create_time dict to prompt field in /history and /queue (#10741)",
        "author": "ric-yu",
        "email": "richard95yu@gmail.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f91078b1ffa484c424f78814f54de4d5846e4daa",
        "short_hash": "f91078b1",
        "date": "2025-11-14T02:05:26",
        "timestamp": 1763057126,
        "message": "add PR template for API-Nodes (#10736)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 2,
        "additions": 79,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "3b3ef9a77ac03ed516a45063f9736f33085cecca",
        "short_hash": "3b3ef9a7",
        "date": "2025-11-13T07:26:52",
        "timestamp": 1762990012,
        "message": "Quantized Ops fixes (#10715)\n\n* offload support, bug fixes, remove mixins\n\n* add readme",
        "author": "contentis",
        "email": "lspindler@nvidia.com",
        "files_changed": 3,
        "additions": 219,
        "deletions": 25,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "8b0b93df51d04f08eb779cb84dc331fa18b43ae8",
        "short_hash": "8b0b93df",
        "date": "2025-11-13T06:04:41",
        "timestamp": 1762985081,
        "message": "Update Python 3.14 compatibility notes in README  (#10730)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "1c7eaeca1013e4315f36e0d4d274faa106001121",
        "short_hash": "1c7eaeca",
        "date": "2025-11-13T05:20:53",
        "timestamp": 1762982453,
        "message": "qwen: reduce VRAM usage (#10725)\n\nClean up a bunch of stacked and no-longer-needed tensors on the QWEN\nVRAM peak (currently FFN).\n\nWith this I go from OOMing at B=37x1328x1328 to being able to\nsuccesfully run B=47 (RTX5090).",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 1,
        "additions": 12,
        "deletions": 8,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "18e7d6dba5f1012d4cf09e8f777dc85d56ff25c0",
        "short_hash": "18e7d6db",
        "date": "2025-11-13T05:19:53",
        "timestamp": 1762982393,
        "message": "mm/mp: always unload re-used but modified models (#10724)\n\nThe partial unloader path in model re-use flow skips straight to the\nactual unload without any check of the patching UUID. This means that\nif you do an upscale flow with a model patch on an existing model, it\nwill not apply your patchings.\n\nFix by delaying the partial_unload until after the uuid checks. This\nis done by making partial_unload a model of partial_load where extra_mem\nis -ve.",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 2,
        "additions": 4,
        "deletions": 4,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e1d85e7577d8f6355bd4cb3449bcb0a7e5f80cb8",
        "short_hash": "e1d85e75",
        "date": "2025-11-13T04:21:05",
        "timestamp": 1762978865,
        "message": "Update README.md for Intel Arc GPU installation, remove IPEX (#10729)\n\nIPEX is no longer needed for Intel Arc GPUs.  Removing instruction to setup ipex.",
        "author": "Qiacheng Li",
        "email": "choliaky@gmail.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 5,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "119941174704081a16a4c3f303d99f2fb1e95cde",
        "short_hash": "11994117",
        "date": "2025-11-12T08:33:30",
        "timestamp": 1762907610,
        "message": "Don't pin tensor if not a torch.nn.parameter.Parameter (#10718)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 6,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "5ebcab3c7d974963a89cecd37296a22fdb73bd2b",
        "short_hash": "5ebcab3c",
        "date": "2025-11-11T04:35:29",
        "timestamp": 1762806929,
        "message": "Update CI workflow to remove dead macOS runner. (#10704)\n\n* Update CI workflow to remove dead macOS runner.\n\n* revert\n\n* revert",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 11,
        "deletions": 9,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "c350009236e5d172a3050c04043ea70a301378ca",
        "short_hash": "c3500092",
        "date": "2025-11-10T11:52:11",
        "timestamp": 1762746731,
        "message": "ops: Put weight cast on the offload stream (#10697)\n\nThis needs to be on the offload stream. This reproduced a black screen\nwith low resolution images on a slow bus when using FP8.",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "dea899f22125d38a8b48147d6cce89a2b659fdeb",
        "short_hash": "dea899f2",
        "date": "2025-11-10T07:51:33",
        "timestamp": 1762732293,
        "message": "Unload weights if vram usage goes up between runs. (#10690)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 2,
        "additions": 22,
        "deletions": 9,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e632e5de281b91dd7199636dd6d82126fbfb07d5",
        "short_hash": "e632e5de",
        "date": "2025-11-10T07:06:39",
        "timestamp": 1762729599,
        "message": "Add logging for model unloading. (#10692)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "2abd2b5c2049a9625b342bcb7decedd5d1645f66",
        "short_hash": "2abd2b5c",
        "date": "2025-11-09T04:52:02",
        "timestamp": 1762635122,
        "message": "Make ScaleROPE node work on Flux. (#10686)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 17,
        "deletions": 5,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "a1a70362ca376cff05a0514e0ce771ab26d92fd9",
        "short_hash": "a1a70362",
        "date": "2025-11-08T00:15:05",
        "timestamp": 1762532105,
        "message": "Only unpin tensor if it was pinned by ComfyUI (#10677)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 10,
        "deletions": 5,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "cf97b033ee80cf245b4592d42f89e6de67e409a4",
        "short_hash": "cf97b033",
        "date": "2025-11-07T10:20:48",
        "timestamp": 1762482048,
        "message": "mm: guard against double pin and unpin explicitly (#10672)\n\nAs commented, if you let cuda be the one to detect double pin/unpinning\nit actually creates an asyc GPU error.",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 1,
        "additions": 12,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "eb1c42f6498ce44aef4dbed3bb665ac98a28254d",
        "short_hash": "eb1c42f6",
        "date": "2025-11-07T09:24:28",
        "timestamp": 1762478668,
        "message": "Tell users they need to upload their logs in bug reports. (#10671)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 5,
        "deletions": 3,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e05c90712670fa4a2ffebd44046fc78747193a36",
        "short_hash": "e05c9071",
        "date": "2025-11-06T17:11:30",
        "timestamp": 1762420290,
        "message": "Clarify release cycle. (#10667)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "09dc24c8a982776abd5cb2f71e3d041139e1d5b2",
        "short_hash": "09dc24c8",
        "date": "2025-11-06T08:11:15",
        "timestamp": 1762387875,
        "message": "Pinned mem also seems to work on AMD. (#10658)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "1d69245981f9fb3861018613246042296d887dd3",
        "short_hash": "1d692459",
        "date": "2025-11-06T07:08:13",
        "timestamp": 1762384093,
        "message": "Enable pinned memory by default on Nvidia. (#10656)\n\nRemoved the --fast pinned_memory flag.\n\nYou can use --disable-pinned-memory to disable it. Please report if it\ncauses any issues.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 2,
        "additions": 11,
        "deletions": 14,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "97f198e4215680a83749ba95849f3cdcfa7aa64a",
        "short_hash": "97f198e4",
        "date": "2025-11-06T07:07:35",
        "timestamp": 1762384055,
        "message": "Fix qwen controlnet regression. (#10657)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "bda0eb2448135797d5a72f7236ce26d07e555baf",
        "short_hash": "bda0eb24",
        "date": "2025-11-05T18:16:00",
        "timestamp": 1762337760,
        "message": "feat(API-nodes): move Rodin3D nodes to new client; removed old api client.py (#10645)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 9,
        "additions": 234,
        "deletions": 1347,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "c4a6b389de1014471a75a46ee57d2fdac4f8df93",
        "short_hash": "c4a6b389",
        "date": "2025-11-05T11:47:35",
        "timestamp": 1762314455,
        "message": "Lower ltxv mem usage to what it was before previous pr. (#10643)\n\nBring back qwen behavior to what it was before previous pr.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 2,
        "additions": 12,
        "deletions": 12,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "4cd881866bad0cde70273cc123d725693c1f2759",
        "short_hash": "4cd88186",
        "date": "2025-11-05T09:10:11",
        "timestamp": 1762305011,
        "message": "Use single apply_rope function across models (#10547)",
        "author": "contentis",
        "email": "lspindler@nvidia.com",
        "files_changed": 5,
        "additions": 58,
        "deletions": 79,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "265adad858e1f31b66cd3523a02b16f5d34ced52",
        "short_hash": "265adad8",
        "date": "2025-11-05T08:42:23",
        "timestamp": 1762303343,
        "message": "ComfyUI version v0.3.68",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "7f3e4d486cd77c3ad30eb4714ec18bdaf29e2b5c",
        "short_hash": "7f3e4d48",
        "date": "2025-11-05T06:37:50",
        "timestamp": 1762295870,
        "message": "Limit amount of pinned memory on windows to prevent issues. (#10638)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 28,
        "deletions": 4,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "a389ee01bb7ba5174729906a7f85bd08b5c2cb87",
        "short_hash": "a389ee01",
        "date": "2025-11-05T06:14:10",
        "timestamp": 1762294450,
        "message": "caching: Handle None outputs tuple case (#10637)",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "9c71a667904a049975531f2a7dd55f4a8fc92652",
        "short_hash": "9c71a667",
        "date": "2025-11-05T02:51:53",
        "timestamp": 1762282313,
        "message": "chore: update workflow templates to v0.2.11 (#10634)",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "af4b7b5edb339a15aa443e32aefbceac1810baa0",
        "short_hash": "af4b7b5e",
        "date": "2025-11-04T11:14:20",
        "timestamp": 1762226060,
        "message": "More fp8 torch.compile regressions fixed. (#10625)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 35,
        "deletions": 19,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "0f4ef3afa0772ad11d6d72ad21fb1e089c2fcf5f",
        "short_hash": "0f4ef3af",
        "date": "2025-11-04T10:47:14",
        "timestamp": 1762224434,
        "message": "This seems to slow things down slightly on Linux. (#10624)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6b88478f9fe0874c0e17468c9fca3a0a84e6c781",
        "short_hash": "6b88478f",
        "date": "2025-11-04T08:22:10",
        "timestamp": 1762215730,
        "message": "Bring back fp8 torch compile performance to what it should be. (#10622)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 39,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e199c8cc6758d388792fd66b99e8de832814ff91",
        "short_hash": "e199c8cc",
        "date": "2025-11-04T06:58:24",
        "timestamp": 1762210704,
        "message": "Fixes (#10621)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "0652cb8e2d343f68e38285755835c77bda7f6389",
        "short_hash": "0652cb8e",
        "date": "2025-11-04T06:37:12",
        "timestamp": 1762209432,
        "message": "Speed up torch.compile (#10620)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 0,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "958a17199ac519504e390ea0d53295ceb8cbd2c1",
        "short_hash": "958a1719",
        "date": "2025-11-04T06:08:30",
        "timestamp": 1762207710,
        "message": "People should update their pytorch versions. (#10618)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 4,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e974e554ca23be505b72bc9c1614f4285c1db6e3",
        "short_hash": "e974e554",
        "date": "2025-11-04T02:59:44",
        "timestamp": 1762196384,
        "message": "chore: update embedded docs to v0.3.1 (#10614)",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "4e2110c794b187c9326d604e7c0b0a4fad81148a",
        "short_hash": "4e2110c7",
        "date": "2025-11-03T16:29:08",
        "timestamp": 1762158548,
        "message": "feat(Pika-API-nodes): use new API client (#10608)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 3,
        "additions": 157,
        "deletions": 224,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e617cddf244e4b789afba4b4ece01661b12fdde5",
        "short_hash": "e617cddf",
        "date": "2025-11-03T16:28:13",
        "timestamp": 1762158493,
        "message": "convert nodes_openai.py to V3 schema (#10604)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 4,
        "additions": 474,
        "deletions": 700,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "1f3f7a2823017ad193e060d9221fb6a52f2eba3a",
        "short_hash": "1f3f7a28",
        "date": "2025-11-03T16:21:47",
        "timestamp": 1762158107,
        "message": "convert nodes_hypernetwork.py to V3 schema (#10583)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 33,
        "deletions": 15,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "88df172790b8ed7b2e6ea7c0f0bd63ca3553921b",
        "short_hash": "88df1727",
        "date": "2025-11-03T16:16:40",
        "timestamp": 1762157800,
        "message": "fix(caching): treat bytes as hashable (#10567)",
        "author": "EverNebula",
        "email": "sfpxxwhb@qq.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6d6a18b0b730351416556eeb0990ab219ffec189",
        "short_hash": "6d6a18b0",
        "date": "2025-11-03T16:04:56",
        "timestamp": 1762157096,
        "message": "fix(api-nodes-cloud): stop using sub-folder and absolute path for output of Rodin3D nodes (#10556)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 5,
        "deletions": 6,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "97ff9fae7e728cffdfc3aee6d72aa1e0d0b78702",
        "short_hash": "97ff9fae",
        "date": "2025-11-03T02:14:04",
        "timestamp": 1762107244,
        "message": "Clarify help text for --fast argument (#10609)\n\nUpdated help text for the --fast argument to clarify potential risks.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "135fa49ec23320834f774cf3def9e51ad3773f86",
        "short_hash": "135fa49e",
        "date": "2025-11-02T06:48:53",
        "timestamp": 1762037333,
        "message": "Small speed improvements to --async-offload (#10593)\n\n* ops: dont take an offload stream if you dont need one\n\n* ops: prioritize mem transfer\n\nThe async offload streams reason for existence is to transfer from\nRAM to GPU. The post processing compute steps are a bonus on the side\nstream, but if the compute stream is running a long kernel, it can\nstall the side stream, as it wait to type-cast the bias before\ntransferring the weight. So do a pure xfer of the weight straight up,\nthen do everything bias, then go back to fix the weight type and do\nweight patches.",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 1,
        "additions": 13,
        "deletions": 8,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "44869ff786dc90b36172fd766c9a110e4c40c04b",
        "short_hash": "44869ff7",
        "date": "2025-11-02T05:25:59",
        "timestamp": 1762032359,
        "message": "Fix issue with pinned memory. (#10597)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "20182a393f43ab1fdf798f8da6aac0ef6116e7e6",
        "short_hash": "20182a39",
        "date": "2025-11-02T03:14:06",
        "timestamp": 1762024446,
        "message": "convert StabilityAI to use new API client (#10582)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 2,
        "additions": 49,
        "deletions": 136,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "5f109fe6a06a3462b31a066bcfd650de67d66102",
        "short_hash": "5f109fe6",
        "date": "2025-11-02T03:13:39",
        "timestamp": 1762024419,
        "message": "added 12s-20s as available output durations for the LTXV API nodes (#10570)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 10,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "c58c13b2bad6df0de93cc0cf107e96522a3cb5b3",
        "short_hash": "c58c13b2",
        "date": "2025-11-01T12:25:17",
        "timestamp": 1761971117,
        "message": "Fix torch compile regression on fp8 ops. (#10580)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 4,
        "additions": 43,
        "deletions": 36,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "7f374e42c833c69c71605507b90f79cc26d14a71",
        "short_hash": "7f374e42",
        "date": "2025-11-01T03:41:40",
        "timestamp": 1761939700,
        "message": "ScaleROPE now works on Lumina models. (#10578)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 16,
        "deletions": 4,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "27d1bd882925e3bbdffb405cea098ac52bb20ac5",
        "short_hash": "27d1bd88",
        "date": "2025-10-31T10:51:58",
        "timestamp": 1761879118,
        "message": "Fix rope scaling. (#10560)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 3,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "614cf9805e1056216487a2d1b1a07206d77f87e7",
        "short_hash": "614cf980",
        "date": "2025-10-31T10:11:38",
        "timestamp": 1761876698,
        "message": "Add a ScaleROPE node. Currently only works on WAN models. (#10559)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 4,
        "additions": 77,
        "deletions": 4,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "513b0c46fba3bf40191d684ff81207ad935f1717",
        "short_hash": "513b0c46",
        "date": "2025-10-31T05:39:02",
        "timestamp": 1761860342,
        "message": "Add RAM Pressure cache mode (#10454)\n\n* execution: Roll the UI cache into the outputs\n\nCurrently the UI cache is parallel to the output cache with\nexpectations of being a content superset of the output cache.\nAt the same time the UI and output cache are maintained completely\nseperately, making it awkward to free the output cache content without\nchanging the behaviour of the UI cache.\n\nThere are two actual users (getters) of the UI cache. The first is\nthe case of a direct content hit on the output cache when executing a\nnode. This case is very naturally handled by merging the UI and outputs\ncache.\n\nThe second case is the history JSON generation at the end of the prompt.\nThis currently works by asking the cache for all_node_ids and then\npulling the cache contents for those nodes. all_node_ids is the nodes\nof the dynamic prompt.\n\nSo fold the UI cache into the output cache. The current UI cache setter\nnow writes to a prompt-scope dict. When the output cache is set, just\nget this value from the dict and tuple up with the outputs.\n\nWhen generating the history, simply iterate prompt-scope dict.\n\nThis prepares support for more complex caching strategies (like RAM\npressure caching) where less than 1 workflow will be cached and it\nwill be desirable to keep the UI cache and output cache in sync.\n\n* sd: Implement RAM getter for VAE\n\n* model_patcher: Implement RAM getter for ModelPatcher\n\n* sd: Implement RAM getter for CLIP\n\n* Implement RAM Pressure cache\n\nImplement a cache sensitive to RAM pressure. When RAM headroom drops\ndown below a certain threshold, evict RAM-expensive nodes from the\ncache.\n\nModels and tensors are measured directly for RAM usage. An OOM score\nis then computed based on the RAM usage of the node.\n\nNote the due to indirection through shared objects (like a model\npatcher), multiple nodes can account the same RAM as their individual\nusage. The intent is this will free chains of nodes particularly\nmodel loaders and associate loras as they all score similar and are\nsorted in close to each other.\n\nHas a bias towards unloading model nodes mid flow while being able\nto keep results like text encodings and VAE.\n\n* execution: Convert the cache entry to NamedTuple\n\nAs commented in review.\n\nConvert this to a named tuple and abstract away the tuple type\ncompletely from graph.py.",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 7,
        "additions": 157,
        "deletions": 38,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "dfac94695be95076d8028d04005a744f3ec0de8d",
        "short_hash": "dfac9469",
        "date": "2025-10-31T01:22:35",
        "timestamp": 1761844955,
        "message": "fix img2img operation in Dall2 node (#10552)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "163b629c70a349c7d1e91eebc5365713e770af8a",
        "short_hash": "163b629c",
        "date": "2025-10-30T14:49:03",
        "timestamp": 1761806943,
        "message": "use new API client in Pixverse and Ideogram nodes (#10543)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 12,
        "additions": 220,
        "deletions": 459,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "998bf60bebd03e57a55e106434657849342b733f",
        "short_hash": "998bf60b",
        "date": "2025-10-30T07:37:06",
        "timestamp": 1761781026,
        "message": "Add units/info for the numbers displayed on 'load completely' and 'load partially' log messages (#10538)",
        "author": "Jedrzej Kosinski",
        "email": "kosinkadink1@gmail.com",
        "files_changed": 1,
        "additions": 4,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "906c0899575a83ac69bb095e835fdec748891da4",
        "short_hash": "906c0899",
        "date": "2025-10-30T07:29:01",
        "timestamp": 1761780541,
        "message": "Fix small performance regression with fp8 fast and scaled fp8. (#10537)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 2,
        "additions": 8,
        "deletions": 3,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "25de7b1bfa22dd98922f047a1342cc97f8e46c5b",
        "short_hash": "25de7b1b",
        "date": "2025-10-30T05:20:27",
        "timestamp": 1761772827,
        "message": "Try to fix slow load issue on low ram hardware with pinned mem. (#10536)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 8,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "ab7ab5be23fb9b71d1790f424e7dcf91dc1fe0cc",
        "short_hash": "ab7ab5be",
        "date": "2025-10-30T05:17:46",
        "timestamp": 1761772666,
        "message": "Fix Race condition in --async-offload that can cause corruption (#10501)\n\n* mm: factor out the current stream getter\n\nMake this a reusable function.\n\n* ops: sync the offload stream with the consumption of w&b\n\nThis sync is nessacary as pytorch will queue cuda async frees on the\nsame stream as created to tensor. In the case of async offload, this\nwill be on the offload stream.\n\nWeights and biases can go out of scope in python which then\ntriggers the pytorch garbage collector to queue the free operation on\nthe offload stream possible before the compute stream has used the\nweight. This causes a use after free on weight data leading to total\ncorruption of some workflows.\n\nSo sync the offload stream with the compute stream after the weight\nhas been used so the free has to wait for the weight to be used.\n\nThe cast_bias_weight is extended in a backwards compatible way with\nthe new behaviour opt-in on a defaulted parameter. This handles\ncustom node packs calling cast_bias_weight and defeatures\nasync-offload for them (as they do not handle the race).\n\nThe pattern is now:\n\ncast_bias_weight(... , offloadable=True) #This might be offloaded\nthing(weight, bias, ...)\nuncast_bias_weight(...)\n\n* controlnet: adopt new cast_bias_weight synchronization scheme\n\nThis is nessacary for safe async weight offloading.\n\n* mm: sync the last stream in the queue, not the next\n\nCurrently this peeks ahead to sync the next stream in the queue of\nstreams with the compute stream. This doesnt allow a lot of\nparallelization, as then end result is you can only get one weight load\nahead regardless of how many streams you have.\n\nRotate the loop logic here to synchronize the end of the queue before\nreturning the next stream. This allows weights to be loaded ahead of the\ncompute streams position.",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 3,
        "additions": 114,
        "deletions": 52,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "ec4fc2a09a390d0d81500c51fb9e4d8a7a5ce1fc",
        "short_hash": "ec4fc2a0",
        "date": "2025-10-30T03:48:06",
        "timestamp": 1761767286,
        "message": "Fix case of weights not being unpinned. (#10533)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "1a58087ac2eb64be3645934d0025aafaa5bdce38",
        "short_hash": "1a58087a",
        "date": "2025-10-30T03:43:51",
        "timestamp": 1761767031,
        "message": "Reduce memory usage for fp8 scaled op. (#10531)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6c14f3afac0ea28dba24fe8783e7c1f09c03b31f",
        "short_hash": "6c14f3af",
        "date": "2025-10-30T02:14:56",
        "timestamp": 1761761696,
        "message": "use new API client in Luma and Minimax nodes (#10528)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 7,
        "additions": 286,
        "deletions": 519,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e525673f7201b6c49af0fa0e6baf44e4e98bb10c",
        "short_hash": "e525673f",
        "date": "2025-10-29T12:37:00",
        "timestamp": 1761712620,
        "message": "Fix issue. (#10527)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "3fa7a5c04ae69ad168a875e8d3d453783d60899d",
        "short_hash": "3fa7a5c0",
        "date": "2025-10-29T12:21:01",
        "timestamp": 1761711661,
        "message": "Speed up offloading using pinned memory. (#10526)\n\nTo enable this feature use: --fast pinned_memory",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 3,
        "additions": 56,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "210f7a1ba580d57d817ca68346cb72b8d0a26ad2",
        "short_hash": "210f7a1b",
        "date": "2025-10-29T05:38:05",
        "timestamp": 1761687485,
        "message": "convert nodes_recraft.py to V3 schema (#10507)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 572,
        "deletions": 721,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "d202c2ba7404affd58a2199aeb514b3cc48e0ef3",
        "short_hash": "d202c2ba",
        "date": "2025-10-29T04:22:08",
        "timestamp": 1761682928,
        "message": "execution: Allow a subgraph nodes to execute multiple times (#10499)\n\nIn the case of --cache-none lazy and subgraph execution can cause\nanything to be run multiple times per workflow. If that rerun nodes is\nin itself a subgraph generator, this will crash for two reasons.\n\npending_subgraph_results[] does not cleanup entries after their use.\nSo when a pending_subgraph_result is consumed, remove it from the list\nso that if the corresponding node is fully re-executed this misses\nlookup and it fall through to execute the node as it should.\n\nSecondly, theres is an explicit enforcement against dups in the\naddition of subgraphs nodes as ephemerals to the dymprompt. Remove this\nenforcement as the use case is now valid.",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 4,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "8817f8fc148c5a63ffd3f854975df8e72c740540",
        "short_hash": "8817f8fc",
        "date": "2025-10-29T04:20:53",
        "timestamp": 1761682853,
        "message": "Mixed Precision Quantization System (#10498)\n\n* Implement mixed precision operations with a registry design and metadate for quant spec in checkpoint.\n\n* Updated design using Tensor Subclasses\n\n* Fix FP8 MM\n\n* An actually functional POC\n\n* Remove CK reference and ensure correct compute dtype\n\n* Update unit tests\n\n* ruff lint\n\n* Implement mixed precision operations with a registry design and metadate for quant spec in checkpoint.\n\n* Updated design using Tensor Subclasses\n\n* Fix FP8 MM\n\n* An actually functional POC\n\n* Remove CK reference and ensure correct compute dtype\n\n* Update unit tests\n\n* ruff lint\n\n* Fix missing keys\n\n* Rename quant dtype parameter\n\n* Rename quant dtype parameter\n\n* Fix unittests for CPU build",
        "author": "contentis",
        "email": "lspindler@nvidia.com",
        "files_changed": 8,
        "additions": 1030,
        "deletions": 19,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "22e40d2ace0f53da025b3a41cbe4b664ef807097",
        "short_hash": "22e40d2a",
        "date": "2025-10-29T03:08:08",
        "timestamp": 1761678488,
        "message": "Tell users to update their nvidia drivers if portable doesn't start. (#10518)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 3,
        "additions": 3,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "3bea4efc6b23d76c6b0672cd90421a9024e13fdb",
        "short_hash": "3bea4efc",
        "date": "2025-10-28T16:45:45",
        "timestamp": 1761641145,
        "message": "Tell users to update nvidia drivers if problem with portable. (#10510)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "8cf2ba4ba64203551276513068ee81145e90f0bc",
        "short_hash": "8cf2ba4b",
        "date": "2025-10-28T15:23:52",
        "timestamp": 1761636232,
        "message": "Remove comfy api key from queue api. (#10502)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 3,
        "additions": 20,
        "deletions": 10,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b61a40cbc9c2eb648b4d22bb513ed3ab2e2f0fd7",
        "short_hash": "b61a40cb",
        "date": "2025-10-28T15:21:45",
        "timestamp": 1761636105,
        "message": "Bump stable portable to cu130 python 3.13.9 (#10508)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f2bb3230b796f6a486894fc3b597db2c0b9538c9",
        "short_hash": "f2bb3230",
        "date": "2025-10-28T15:03:59",
        "timestamp": 1761635039,
        "message": "ComfyUI version v0.3.67",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "614b8d3345424481d94a22fe7496d908c1a5c526",
        "short_hash": "614b8d33",
        "date": "2025-10-28T15:01:13",
        "timestamp": 1761634873,
        "message": "frontend bump to 1.28.8 (#10506)",
        "author": "Jedrzej Kosinski",
        "email": "kosinkadink1@gmail.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6abc30aae9bd13f31dafd32552a365f2df2cf715",
        "short_hash": "6abc30aa",
        "date": "2025-10-28T13:56:30",
        "timestamp": 1761630990,
        "message": "Update template to 0.2.4 (#10505)",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "55bad303754eb60fa98f3ccf598e95502b819149",
        "short_hash": "55bad303",
        "date": "2025-10-28T13:25:29",
        "timestamp": 1761629129,
        "message": "feat(api-nodes): add LTXV API nodes (#10496)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 2,
        "additions": 192,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "c305deed56a6ed259563b2047d9fcd51471e6590",
        "short_hash": "c305deed",
        "date": "2025-10-28T13:24:16",
        "timestamp": 1761629056,
        "message": "Update template to 0.2.3 (#10503)",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "601ee1775a3c06c9b4de1fa7d808af8625b2fcd5",
        "short_hash": "601ee177",
        "date": "2025-10-28T11:54:00",
        "timestamp": 1761623640,
        "message": "Add a bat to run comfyui portable without api nodes. (#10504)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "c170fd2db598a0bdce56f80e22e83e10ad731421",
        "short_hash": "c170fd2d",
        "date": "2025-10-27T08:23:01",
        "timestamp": 1761524581,
        "message": "Bump portable deps workflow to torch cu130 python 3.13.9 (#10493)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "9d529e53084bdec28f684f3886a26c93598e7338",
        "short_hash": "9d529e53",
        "date": "2025-10-26T14:51:06",
        "timestamp": 1761461466,
        "message": "fix(api-nodes): random issues on Windows by capturing general OSError for retries (#10486)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 3,
        "additions": 10,
        "deletions": 15,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f6bbc1ac846b7d9a73ae50c3a45cf5a41058c54d",
        "short_hash": "f6bbc1ac",
        "date": "2025-10-26T11:07:29",
        "timestamp": 1761448049,
        "message": "Fix mistake. (#10484)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "098a352f136c610071bcb74f13e5b0ca16e6e7b3",
        "short_hash": "098a352f",
        "date": "2025-10-26T08:05:22",
        "timestamp": 1761437122,
        "message": "Add warning for torch-directml usage (#10482)\n\nAdded a warning message about the state of torch-directml.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e86b79ab9ea7e740b80490353f3f5763840ede81",
        "short_hash": "e86b79ab",
        "date": "2025-10-26T05:35:30",
        "timestamp": 1761428130,
        "message": "convert Gemini API nodes to V3 schema (#10476)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 4,
        "additions": 271,
        "deletions": 389,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "426cde37f10dc391f9601ab938e02c0faa42db14",
        "short_hash": "426cde37",
        "date": "2025-10-25T07:56:51",
        "timestamp": 1761350211,
        "message": "Remove useless function (#10472)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 0,
        "deletions": 6,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "dd5af0c5871376c377b2e30f9725b67a768eea6f",
        "short_hash": "dd5af0c5",
        "date": "2025-10-25T06:48:34",
        "timestamp": 1761346114,
        "message": "convert Tripo API nodes to V3 schema (#10469)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 4,
        "additions": 510,
        "deletions": 425,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "388b306a2b48070737b092b51e76de933baee9ad",
        "short_hash": "388b306a",
        "date": "2025-10-24T13:37:16",
        "timestamp": 1761284236,
        "message": "feat(api-nodes): network client v2: async ops, cancellation, downloads, refactor (#10390)\n\n* feat(api-nodes): implement new API client for V3 nodes\n\n* feat(api-nodes): implement new API client for V3 nodes\n\n* feat(api-nodes): implement new API client for V3 nodes\n\n* converted WAN nodes to use new client; polishing\n\n* fix(auth): do not leak authentification for the absolute urls\n\n* convert BFL API nodes to use new API client; remove deprecated BFL nodes\n\n* converted Google Veo nodes\n\n* fix(Veo3.1 model): take into account \"generate_audio\" parameter",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 29,
        "additions": 2933,
        "deletions": 2296,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "24188b3141aace272cb91b85578c76f5a8f70e1c",
        "short_hash": "24188b31",
        "date": "2025-10-24T13:36:30",
        "timestamp": 1761284190,
        "message": "Update template to 0.2.2 (#10461)\n\nFix template typo issue",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "1bcda6df987a6c92b39d8b6d29e0b029450d67d0",
        "short_hash": "1bcda6df",
        "date": "2025-10-24T09:21:14",
        "timestamp": 1761268874,
        "message": "WIP way to support multi multi dimensional latents. (#10456)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 5,
        "additions": 158,
        "deletions": 15,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "a1864c01f29cc43fe6bf823fc3fd46ba2781c2e0",
        "short_hash": "a1864c01",
        "date": "2025-10-23T05:26:22",
        "timestamp": 1761168382,
        "message": "Small readme improvement. (#10442)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "4739d7717fea56750d0ef98c64268d9c1e487d78",
        "short_hash": "4739d771",
        "date": "2025-10-23T03:49:05",
        "timestamp": 1761162545,
        "message": "execution: fold in dependency aware caching / Fix --cache-none with loops/lazy etc (Resubmit) (#10440)\n\n* execution: fold in dependency aware caching\n\nThis makes --cache-none compatiable with lazy and expanded\nsubgraphs.\n\nCurrently the --cache-none option is powered by the\nDependencyAwareCache. The cache attempts to maintain a parallel\ncopy of the execution list data structure, however it is only\nsetup once at the start of execution and does not get meaninigful\nupdates to the execution list.\n\nThis causes multiple problems when --cache-none is used with lazy\nand expanded subgraphs as the DAC does not accurately update its\ncopy of the execution data structure.\n\nDAC has an attempt to handle subgraphs ensure_subcache however\nthis does not accurately connect to nodes outside the subgraph.\nThe current semantics of DAC are to free a node ASAP after the\ndependent nodes are executed.\n\nThis means that if a subgraph refs such a node it will be requed\nand re-executed by the execution_list but DAC wont see it in\nits to-free lists anymore and leak memory.\n\nRather than try and cover all the cases where the execution list\nchanges from inside the cache, move the while problem to the\nexecutor which maintains an always up-to-date copy of the wanted\ndata-structure.\n\nThe executor now has a fast-moving run-local cache of its own.\nEach _to node has its own mini cache, and the cache is unconditionally\nprimed at the time of add_strong_link.\n\nadd_strong_link is called for all of static workflows, lazy links\nand expanded subgraphs so its the singular source of truth for\noutput dependendencies.\n\nIn the case of a cache-hit, the executor cache will hold the non-none\nvalue (it will respect updates if they happen somehow as well).\n\nIn the case of a cache-miss, the executor caches a None and will\nwait for a notification to update the value when the node completes.\n\nWhen a node completes execution, it simply releases its mini-cache\nand in turn its strong refs on its direct anscestor outputs, allowing\nfor ASAP freeing (same as the DependencyAwareCache but a little more\nautomatic).\n\nThis now allows for re-implementation of --cache-none with no cache\nat all. The dependency aware cache was also observing the dependency\nsematics for the objects and UI cache which is not accurate (this\nentire logic was always outputs specific).\n\nThis also prepares for more complex caching strategies (such as RAM\npressure based caching), where a cache can implement any freeing\nstrategy completely independently of the DepedancyAwareness\nrequirement.\n\n* main: re-implement --cache-none as no cache at all\n\nThe execution list now tracks the dependency aware caching more\ncorrectly that the DependancyAwareCache.\n\nChange it to a cache that does nothing.\n\n* test_execution: add --cache-none to the test suite\n\n--cache-none is now expected to work universally. Run it through the\nfull unit test suite. Propagate the server parameterization for whether\nor not the server is capabale of caching, so that the minority of tests\nthat specifically check for cache hits can if else. Hard assert NOT\ncaching in the else to give some coverage of --cache-none expected\nbehaviour to not acutally cache.",
        "author": "rattus",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 5,
        "additions": 102,
        "deletions": 190,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f13cff0be65e35d34876b173bba2fec6bd94746b",
        "short_hash": "f13cff0b",
        "date": "2025-10-22T11:16:16",
        "timestamp": 1761102976,
        "message": "Add custom node published subgraphs endpoint (#10438)\n\n* Add get_subgraphs_dir to ComfyExtension and PUBLISHED_SUBGRAPH_DIRS to nodes.py\n\n* Created initial endpoints, although the returned paths are a bit off currently\n\n* Fix path and actually return real data\n\n* Sanitize returned /api/global_subgraphs entries\n\n* Remove leftover function from early prototyping\n\n* Remove added whitespace\n\n* Add None check for sanitize_entry",
        "author": "Jedrzej Kosinski",
        "email": "kosinkadink1@gmail.com",
        "files_changed": 2,
        "additions": 115,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "9cdc64998f8990aed7688b0ebe89bc3b97733764",
        "short_hash": "9cdc6499",
        "date": "2025-10-22T07:15:23",
        "timestamp": 1761088523,
        "message": "Only disable cudnn on newer AMD GPUs. (#10437)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 10,
        "deletions": 4,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "560b1bdfca77d9441ca2924fd9d6baa8dda05cd7",
        "short_hash": "560b1bdf",
        "date": "2025-10-21T13:12:32",
        "timestamp": 1761023552,
        "message": "ComfyUI version v0.3.66",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b7992f871af38d89a459080caa57cc359ed93a46",
        "short_hash": "b7992f87",
        "date": "2025-10-21T07:03:06",
        "timestamp": 1761001386,
        "message": "Revert \"execution: fold in dependency aware caching / Fix --cache-none with l‚Ä¶\" (#10422)\n\nThis reverts commit b1467da4803017a418c32c159525767f45871ca3.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 5,
        "additions": 190,
        "deletions": 101,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "2c2aa409b01f513de88d2245931e5836ed1cd718",
        "short_hash": "2c2aa409",
        "date": "2025-10-21T03:43:24",
        "timestamp": 1760989404,
        "message": "Log message for cudnn disable on  AMD. (#10418)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "a4787ac83bf6c83eeb459ed80fc9b36f63d2a3a7",
        "short_hash": "a4787ac8",
        "date": "2025-10-21T03:28:36",
        "timestamp": 1760988516,
        "message": "Update template to 0.2.1 (#10413)\n\n* Update template to 0.1.97\n\n* Update template to 0.2.1",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b5c59b763c6b14e1362ec4274b09eca4f3f7091b",
        "short_hash": "b5c59b76",
        "date": "2025-10-20T04:05:46",
        "timestamp": 1760904346,
        "message": "Deprecation warning on unused files (#10387)\n\n* only warn for unused files\n\n* include internal extensions",
        "author": "Christian Byrne",
        "email": "cbyrne@comfy.org",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b4f30bd4087a79b4c4fc89bb67b9889adb866294",
        "short_hash": "b4f30bd4",
        "date": "2025-10-19T13:25:35",
        "timestamp": 1760851535,
        "message": "Pytorch is stupid. (#10398)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "dad076aee68ab676fb390d9663ab9e343824a080",
        "short_hash": "dad076ae",
        "date": "2025-10-19T11:19:52",
        "timestamp": 1760843992,
        "message": "Speed up chroma radiance. (#10395)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "0cf33953a7c951d163088cbfe36c55d1cdf8a718",
        "short_hash": "0cf33953",
        "date": "2025-10-19T11:15:34",
        "timestamp": 1760843734,
        "message": "Fix batch size above 1 giving bad output in chroma radiance. (#10394)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 7,
        "deletions": 16,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "5b80addafd24bda5b2f9f7a35e32dbd40823c3fd",
        "short_hash": "5b80adda",
        "date": "2025-10-19T10:35:46",
        "timestamp": 1760841346,
        "message": "Turn off cuda malloc by default when --fast autotune is turned on. (#10393)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 3,
        "additions": 7,
        "deletions": 6,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "9da397ea2f271080406f0c14cf4f0db7221ddf70",
        "short_hash": "9da397ea",
        "date": "2025-10-18T08:03:28",
        "timestamp": 1760745808,
        "message": "Disable torch compiler for cast_bias_weight function (#10384)\n\n* Disable torch compiler for cast_bias_weight function\n\n* Fix torch compile.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 4,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "92d97380bd02d9883295aeb2d29365cecd9a765e",
        "short_hash": "92d97380",
        "date": "2025-10-18T06:22:59",
        "timestamp": 1760739779,
        "message": "Update Python 3.14 installation instructions (#10385)\n\nRemoved mention of installing pytorch nightly for Python 3.14.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "99ce2a1f66c4bcd500d76cc9a7430f7b2bf32776",
        "short_hash": "99ce2a1f",
        "date": "2025-10-18T05:13:05",
        "timestamp": 1760735585,
        "message": "convert nodes_controlnet.py to V3 schema (#10202)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 59,
        "deletions": 35,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b1467da4803017a418c32c159525767f45871ca3",
        "short_hash": "b1467da4",
        "date": "2025-10-18T04:55:15",
        "timestamp": 1760734515,
        "message": "execution: fold in dependency aware caching / Fix --cache-none with loops/lazy etc (#10368)\n\n* execution: fold in dependency aware caching\n\nThis makes --cache-none compatiable with lazy and expanded\nsubgraphs.\n\nCurrently the --cache-none option is powered by the\nDependencyAwareCache. The cache attempts to maintain a parallel\ncopy of the execution list data structure, however it is only\nsetup once at the start of execution and does not get meaninigful\nupdates to the execution list.\n\nThis causes multiple problems when --cache-none is used with lazy\nand expanded subgraphs as the DAC does not accurately update its\ncopy of the execution data structure.\n\nDAC has an attempt to handle subgraphs ensure_subcache however\nthis does not accurately connect to nodes outside the subgraph.\nThe current semantics of DAC are to free a node ASAP after the\ndependent nodes are executed.\n\nThis means that if a subgraph refs such a node it will be requed\nand re-executed by the execution_list but DAC wont see it in\nits to-free lists anymore and leak memory.\n\nRather than try and cover all the cases where the execution list\nchanges from inside the cache, move the while problem to the\nexecutor which maintains an always up-to-date copy of the wanted\ndata-structure.\n\nThe executor now has a fast-moving run-local cache of its own.\nEach _to node has its own mini cache, and the cache is unconditionally\nprimed at the time of add_strong_link.\n\nadd_strong_link is called for all of static workflows, lazy links\nand expanded subgraphs so its the singular source of truth for\noutput dependendencies.\n\nIn the case of a cache-hit, the executor cache will hold the non-none\nvalue (it will respect updates if they happen somehow as well).\n\nIn the case of a cache-miss, the executor caches a None and will\nwait for a notification to update the value when the node completes.\n\nWhen a node completes execution, it simply releases its mini-cache\nand in turn its strong refs on its direct anscestor outputs, allowing\nfor ASAP freeing (same as the DependencyAwareCache but a little more\nautomatic).\n\nThis now allows for re-implementation of --cache-none with no cache\nat all. The dependency aware cache was also observing the dependency\nsematics for the objects and UI cache which is not accurate (this\nentire logic was always outputs specific).\n\nThis also prepares for more complex caching strategies (such as RAM\npressure based caching), where a cache can implement any freeing\nstrategy completely independently of the DepedancyAwareness\nrequirement.\n\n* main: re-implement --cache-none as no cache at all\n\nThe execution list now tracks the dependency aware caching more\ncorrectly that the DependancyAwareCache.\n\nChange it to a cache that does nothing.\n\n* test_execution: add --cache-none to the test suite\n\n--cache-none is now expected to work universally. Run it through the\nfull unit test suite. Propagate the server parameterization for whether\nor not the server is capabale of caching, so that the minority of tests\nthat specifically check for cache hits can if else. Hard assert NOT\ncaching in the else to give some coverage of --cache-none expected\nbehaviour to not acutally cache.",
        "author": "rattus128",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 5,
        "additions": 101,
        "deletions": 190,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "d8d60b56093a15edc5d25486d387d3c5917dc3d3",
        "short_hash": "d8d60b56",
        "date": "2025-10-17T12:39:37",
        "timestamp": 1760675977,
        "message": "Do batch_slice in EasyCache's apply_cache_diff (#10376)",
        "author": "Jedrzej Kosinski",
        "email": "kosinkadink1@gmail.com",
        "files_changed": 1,
        "additions": 4,
        "deletions": 3,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b1293d50eff5f1ff2e54f73114fbe7c0f9aef8fe",
        "short_hash": "b1293d50",
        "date": "2025-10-17T07:59:56",
        "timestamp": 1760659196,
        "message": "workaround also works on cudnn 91200 (#10375)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "19b466160c1cd43f707769adef6f8ed6e9fd50bf",
        "short_hash": "19b46616",
        "date": "2025-10-17T06:16:03",
        "timestamp": 1760652963,
        "message": "Workaround for nvidia issue where VAE uses 3x more memory on torch 2.9 (#10373)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 19,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "bc0ad9bb49b642e081f99f92d239d634988d52bc",
        "short_hash": "bc0ad9bb",
        "date": "2025-10-17T01:12:50",
        "timestamp": 1760634770,
        "message": "fix(api-nodes): remove \"veo2\" model from Veo3 node (#10372)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "4054b4bf38d11fc0c784c2d19f5fc0ed3bbc7ae4",
        "short_hash": "4054b4bf",
        "date": "2025-10-16T16:13:31",
        "timestamp": 1760602411,
        "message": "feat: deprecated API alert (#10366)",
        "author": "Rizumu Ayaka",
        "email": "rizumu@ayaka.moe",
        "files_changed": 1,
        "additions": 23,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "55ac7d333c55d808be33c590a4a2e6c965d5f9a8",
        "short_hash": "55ac7d33",
        "date": "2025-10-16T11:30:39",
        "timestamp": 1760585439,
        "message": "Bump frontend to 1.28.7 (#10364)",
        "author": "Arjan Singh",
        "email": "1598641+arjansingh@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "afa8a24fe1f81d447b961fdf41f47f9094d28919",
        "short_hash": "afa8a24f",
        "date": "2025-10-16T08:16:09",
        "timestamp": 1760573769,
        "message": "refactor: Replace manual patches merging with merge_nested_dicts (#10360)",
        "author": "Faych",
        "email": "90372299+neverbiasu@users.noreply.github.com",
        "files_changed": 1,
        "additions": 4,
        "deletions": 11,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "493b81e48f4067da95e4cee36d42a3516338da79",
        "short_hash": "493b81e4",
        "date": "2025-10-16T07:47:26",
        "timestamp": 1760572046,
        "message": "Fix order of inputs nested merge_nested_dicts (#10362)",
        "author": "Jedrzej Kosinski",
        "email": "kosinkadink1@gmail.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6b035bfce25b5336ed2a39c72972a8a36a80f9bd",
        "short_hash": "6b035bfc",
        "date": "2025-10-16T06:48:12",
        "timestamp": 1760568492,
        "message": "Latest pytorch stable is cu130 (#10361)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "74b7f0b04ba19926286518b0a0179290b79bfae0",
        "short_hash": "74b7f0b0",
        "date": "2025-10-16T06:41:45",
        "timestamp": 1760568105,
        "message": "feat(api-nodes): add Veo3.1 model (#10357)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 9,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f72c6616b2e91e4021591895192cef8b9d4d1c75",
        "short_hash": "f72c6616",
        "date": "2025-10-16T06:12:25",
        "timestamp": 1760566345,
        "message": "Add TemporalScoreRescaling node (#10351)\n\n* Add TemporalScoreRescaling node\n\n* Mention image generation in tsr_k's tooltip",
        "author": "chaObserv",
        "email": "154517000+chaObserv@users.noreply.github.com",
        "files_changed": 1,
        "additions": 95,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "1c10b33f9bbc75114053bc041851b60767791783",
        "short_hash": "1c10b33f",
        "date": "2025-10-15T12:21:11",
        "timestamp": 1760502071,
        "message": "gfx942 doesn't support fp8 operations. (#10348)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "ddfce1af4fc76768dbdd0cc4fa22d47b20a8b876",
        "short_hash": "ddfce1af",
        "date": "2025-10-15T09:08:23",
        "timestamp": 1760490503,
        "message": "Bump frontend to 1.28.6 (#10345)",
        "author": "Arjan Singh",
        "email": "1598641+arjansingh@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "7a883849ea21003a5a649276a4cd322cb6c2ff0b",
        "short_hash": "7a883849",
        "date": "2025-10-14T14:55:56",
        "timestamp": 1760424956,
        "message": "api-nodes: fixed dynamic pricing format; import comfy_io directly (#10336)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 19,
        "additions": 1331,
        "deletions": 1322,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "84867067ea588e2a3d38a54dc34d86c96d706487",
        "short_hash": "84867067",
        "date": "2025-10-14T14:09:12",
        "timestamp": 1760422152,
        "message": "Python 3.14 instructions. (#10337)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "3374e900d0f310100ebe54944175a36f287110cb",
        "short_hash": "3374e900",
        "date": "2025-10-14T11:43:53",
        "timestamp": 1760413433,
        "message": "Faster workflow cancelling. (#10301)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 12,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "51696e3fdcdfad657cb15854345fbcbbe70eef8d",
        "short_hash": "51696e3f",
        "date": "2025-10-14T11:39:55",
        "timestamp": 1760413195,
        "message": "ComfyUI version 0.3.65",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "dfff7e5332530b7278c1f90c51aed525db53489e",
        "short_hash": "dfff7e53",
        "date": "2025-10-14T10:37:19",
        "timestamp": 1760409439,
        "message": "Better memory estimation for the SD/Flux VAE on AMD. (#10334)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 7,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e4ea3936660a8f8dfa2467e51631362b04ad47e8",
        "short_hash": "e4ea3936",
        "date": "2025-10-14T10:18:58",
        "timestamp": 1760408338,
        "message": "Fix loading old stable diffusion ckpt files on newer numpy. (#10333)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 5,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "c8674bc6e9c0762e9fabe0e7f2762d5c36700963",
        "short_hash": "c8674bc6",
        "date": "2025-10-14T09:19:03",
        "timestamp": 1760404743,
        "message": "Enable RDNA4 pytorch attention on ROCm 7.0 and up. (#10332)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 3,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "3dfdcf66b643b6c191743d3b30fd8198ce690f2d",
        "short_hash": "3dfdcf66",
        "date": "2025-10-14T03:36:26",
        "timestamp": 1760384186,
        "message": "convert nodes_hunyuan.py to V3 schema (#10136)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 153,
        "deletions": 94,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "95ca2e56c82c1c714dba685bd81ebf3f7baf8efa",
        "short_hash": "95ca2e56",
        "date": "2025-10-14T03:23:11",
        "timestamp": 1760383391,
        "message": "WAN2.2: Fix cache VRAM leak on error (#10308)\n\nSame change pattern as 7e8dd275c243ad460ed5015d2e13611d81d2a569\napplied to WAN2.2\n\nIf this suffers an exception (such as a VRAM oom) it will leave the\nencode() and decode() methods which skips the cleanup of the WAN\nfeature cache. The comfy node cache then ultimately keeps a reference\nthis object which is in turn reffing large tensors from the failed\nexecution.\n\nThe feature cache is currently setup at a class variable on the\nencoder/decoder however, the encode and decode functions always clear\nit on both entry and exit of normal execution.\n\nIts likely the design intent is this is usable as a streaming encoder\nwhere the input comes in batches, however the functions as they are\ntoday don't support that.\n\nSo simplify by bringing the cache back to local variable, so that if\nit does VRAM OOM the cache itself is properly garbage when the\nencode()/decode() functions dissappear from the stack.",
        "author": "rattus128",
        "email": "46076784+rattus128@users.noreply.github.com",
        "files_changed": 1,
        "additions": 14,
        "deletions": 23,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "27ffd12c45d4237338fe8789779313db9bab59f1",
        "short_hash": "27ffd12c",
        "date": "2025-10-14T03:14:52",
        "timestamp": 1760382892,
        "message": "add indent=4 kwarg to json.dumps() (#10307)",
        "author": "Daniel Harte",
        "email": "norgeous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e693e4db6a2df8482599eed348be15f87799b910",
        "short_hash": "e693e4db",
        "date": "2025-10-14T02:57:27",
        "timestamp": 1760381847,
        "message": "Always set diffusion model to eval() mode. (#10331)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "d68ece7301c63da11e0b565da0ecc2900c8ea447",
        "short_hash": "d68ece73",
        "date": "2025-10-13T11:54:41",
        "timestamp": 1760327681,
        "message": "Update the extra_model_paths.yaml.example (#10319)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 23,
        "deletions": 20,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "894837de9ae9efd87ea81a29af66a9c29628ef47",
        "short_hash": "894837de",
        "date": "2025-10-13T11:35:33",
        "timestamp": 1760326533,
        "message": "update extra models paths example (#10316)",
        "author": "Christian Byrne",
        "email": "cbyrne@comfy.org",
        "files_changed": 1,
        "additions": 6,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "fdc92863b6dc6d0edff85e6dbb6a2382046c020d",
        "short_hash": "fdc92863",
        "date": "2025-10-13T11:32:02",
        "timestamp": 1760326322,
        "message": "Update node docs to 0.3.0 (#10318)",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "a125cd84b054a57729b5eecab930ca9408719832",
        "short_hash": "a125cd84",
        "date": "2025-10-12T12:28:01",
        "timestamp": 1760243281,
        "message": "Improve AMD performance. (#10302)\n\nI honestly have no idea why this improves things but it does.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 5,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "84e9ce32c6d9d340404ee0798a426dae52bbee8b",
        "short_hash": "84e9ce32",
        "date": "2025-10-12T10:57:23",
        "timestamp": 1760237843,
        "message": "Implement the mmaudio VAE. (#10300)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 9,
        "additions": 1247,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f43b8ab2a2eda034651187222829f72aa82eae6c",
        "short_hash": "f43b8ab2",
        "date": "2025-10-12T01:27:22",
        "timestamp": 1760203642,
        "message": "Update template to 0.1.95 (#10294)",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "14d642acd66973c81a806dc6f0562d89b4ba3506",
        "short_hash": "14d642ac",
        "date": "2025-10-11T07:21:40",
        "timestamp": 1760138500,
        "message": "feat(api-nodes): add price extractor feature; small fixes to Kling & Pika nodes (#10284)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 3,
        "additions": 33,
        "deletions": 17,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "aa895db7e876401eb3b1d2601f49d6f2aee770ca",
        "short_hash": "aa895db7",
        "date": "2025-10-11T07:17:20",
        "timestamp": 1760138240,
        "message": "feat(GeminiImage-ApiNode): add aspect_ratio and release version of model (#10255)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 2,
        "additions": 28,
        "deletions": 13,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "cdfc25a1605add750a3b1a83360b84e8e95324c6",
        "short_hash": "cdfc25a1",
        "date": "2025-10-11T05:33:51",
        "timestamp": 1760132031,
        "message": "Fix save audio nodes saving mono audio as stereo. (#10289)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 5,
        "deletions": 4,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "81e4dac107c24b1655babc47c99c33551c96a644",
        "short_hash": "81e4dac1",
        "date": "2025-10-10T07:08:40",
        "timestamp": 1760051320,
        "message": "convert nodes_upscale_model.py to V3 schema (#10149)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 2,
        "additions": 51,
        "deletions": 27,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "90853fb9cd42ebbee7b3fcf46e518e5632912b11",
        "short_hash": "90853fb9",
        "date": "2025-10-10T07:07:17",
        "timestamp": 1760051237,
        "message": "convert nodes_flux to V3 schema (#10122)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 116,
        "deletions": 75,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f1dd6e50f891b1d2b17e4b8d26d422634fe49595",
        "short_hash": "f1dd6e50",
        "date": "2025-10-10T07:02:40",
        "timestamp": 1760050960,
        "message": "Fix bug with applying loras on fp8 scaled without fp8 ops. (#10279)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 8,
        "deletions": 4,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "fc0fbf141c7deb444fe730af2f2db8e2beddaf60",
        "short_hash": "fc0fbf14",
        "date": "2025-10-10T06:18:23",
        "timestamp": 1760048303,
        "message": "convert nodes_sd3.py and nodes_slg.py to V3 schema (#10162)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 2,
        "additions": 228,
        "deletions": 130,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "f3d5d328a39d2f264b35d43f0e9c5a0b4d780c2f",
        "short_hash": "f3d5d328",
        "date": "2025-10-10T06:15:03",
        "timestamp": 1760048103,
        "message": "fix(v3,api-nodes): V3 schema typing; corrected Pika API nodes (#10265)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 8,
        "additions": 310,
        "deletions": 313,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "139addd53c6cab97fb0ac28d1c895b3ecc7dff6c",
        "short_hash": "139addd5",
        "date": "2025-10-10T04:37:35",
        "timestamp": 1760042255,
        "message": "More surgical fix for #10267 (#10276)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 2,
        "additions": 24,
        "deletions": 8,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "cbee7d33909f168a08ab7e53d897ea284a304d84",
        "short_hash": "cbee7d33",
        "date": "2025-10-09T14:14:00",
        "timestamp": 1759990440,
        "message": "convert nodes_latent.py to V3 schema (#10160)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 226,
        "deletions": 172,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6732014a0a99e85389e5c32e87bdff9e31cdcfd1",
        "short_hash": "6732014a",
        "date": "2025-10-09T14:13:15",
        "timestamp": 1759990395,
        "message": "convert nodes_compositing.py to V3 schema (#10174)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 69,
        "deletions": 60,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "989f715d92678e02b0a2db948e0610027cee7d96",
        "short_hash": "989f715d",
        "date": "2025-10-09T14:11:45",
        "timestamp": 1759990305,
        "message": "convert nodes_lora_extract.py to V3 schema (#10182)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 42,
        "deletions": 28,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "2ba8d7cce8b6d78efa4b853ae8df187bb13061a3",
        "short_hash": "2ba8d7cc",
        "date": "2025-10-09T14:10:23",
        "timestamp": 1759990223,
        "message": "convert nodes_model_downscale.py to V3 schema (#10199)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 40,
        "deletions": 23,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "51fb505ffa7cdae113ef4303f9ef45a06d668a90",
        "short_hash": "51fb505f",
        "date": "2025-10-09T14:06:56",
        "timestamp": 1759990016,
        "message": "feat(api-nodes, pylint): use lazy formatting in logging functions (#10248)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 9,
        "additions": 50,
        "deletions": 46,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "72c2071972d3207ed92bc20535299c5f39622818",
        "short_hash": "72c20719",
        "date": "2025-10-09T08:30:41",
        "timestamp": 1759969841,
        "message": "Mvly/node update (#10042)\n\n* updated V2V node to allow for control image input\nexposing steps in v2v\nfixing guidance_scale as input parameter\n\nTODO: allow for motion_intensity as input param.\n\n* refactor: comment out unsupported resolution and adjust default values in video nodes\n\n* set control_after_generate\n\n* adding new defaults\n\n* fixes\n\n* changed control_after_generate back to True\n\n* changed control_after_generate back to False\n\n---------\n\nCo-authored-by: thorsten <thorsten@tripod-digital.co.nz>",
        "author": "Jedrzej Kosinski",
        "email": "kosinkadink1@gmail.com",
        "files_changed": 1,
        "additions": 37,
        "deletions": 23,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6e59934089df3375e39db174340b6a937b226c83",
        "short_hash": "6e599340",
        "date": "2025-10-09T05:49:02",
        "timestamp": 1759960142,
        "message": "Refactor model sampling sigmas code. (#10250)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 17,
        "deletions": 11,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "3e0eb8d33f9a65f2a01430f1b4a1535348af881c",
        "short_hash": "3e0eb8d3",
        "date": "2025-10-08T15:14:04",
        "timestamp": 1759907644,
        "message": "feat(V3-io): allow Enum classes for Combo options (#10237)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 9,
        "additions": 88,
        "deletions": 74,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "637221995f7424a561bd825de3e61ea117dfe1e3",
        "short_hash": "63722199",
        "date": "2025-10-08T12:53:43",
        "timestamp": 1759899223,
        "message": "ComfyUI version 0.3.64",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "51697d50dc94005b1c279eb0cf45207697946020",
        "short_hash": "51697d50",
        "date": "2025-10-08T10:48:51",
        "timestamp": 1759891731,
        "message": "update template to 0.1.94 (#10253)",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "19f595b788bd227004a5f7232f3b5895b46411ea",
        "short_hash": "19f595b7",
        "date": "2025-10-08T08:54:00",
        "timestamp": 1759884840,
        "message": "Bump frontend to 1.27.10 (#10252)",
        "author": "filtered",
        "email": "176114999+webfiltered@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "8a15568f10c0622a7281c32fadffc51511e53c10",
        "short_hash": "8a15568f",
        "date": "2025-10-08T07:55:23",
        "timestamp": 1759881323,
        "message": "Temp fix for LTXV custom nodes. (#10251)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 8,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "9e984c48bc6a1d1c82231c46542995dbf5a265d7",
        "short_hash": "9e984c48",
        "date": "2025-10-08T05:11:37",
        "timestamp": 1759871497,
        "message": "feat(api-nodes): add Sora2 API node (#10249)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 3,
        "additions": 194,
        "deletions": 5,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "fc34c3d1125e970699dcb311323839ed6dda4985",
        "short_hash": "fc34c3d1",
        "date": "2025-10-08T04:15:32",
        "timestamp": 1759868132,
        "message": "fix(ReCraft-API-node): allow custom multipart parser to return FormData (#10244)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 2,
        "additions": 32,
        "deletions": 13,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "8aea746212dc1bb1601b4dc5e8c8093d2221d89c",
        "short_hash": "8aea7462",
        "date": "2025-10-07T10:08:08",
        "timestamp": 1759802888,
        "message": "Implement gemma 3 as a text encoder. (#10241)\n\nNot useful yet.",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 4,
        "additions": 142,
        "deletions": 28,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "8c1991042795d06c7ccfd5d1931eb994044c75ef",
        "short_hash": "8c199104",
        "date": "2025-10-07T07:26:52",
        "timestamp": 1759793212,
        "message": "convert nodes_kling.py to V3 schema (#10236)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 1053,
        "deletions": 1135,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "e77e0a8f8fdcdc53deb8207e0d5b16ca56824a4b",
        "short_hash": "e77e0a8f",
        "date": "2025-10-07T07:20:26",
        "timestamp": 1759792826,
        "message": "convert nodes_pika.py to V3 schema (#10216)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 381,
        "deletions": 414,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "a49007a7b07abfdcb10bc10c23514c48935ea914",
        "short_hash": "a49007a7",
        "date": "2025-10-07T07:13:43",
        "timestamp": 1759792423,
        "message": "fix(api-nodes): allow negative_prompt PixVerse to be multiline (#10196)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 3,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6ae35158013e50698e680344ab1f54de0d59fef0",
        "short_hash": "6ae35158",
        "date": "2025-10-07T07:05:57",
        "timestamp": 1759791957,
        "message": "fix(api-nodes): enable more pylint rules (#10213)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 4,
        "additions": 7,
        "deletions": 12,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "6bd3f8eb9ff2d7c74e8ca75ad1f854a6b256b714",
        "short_hash": "6bd3f8eb",
        "date": "2025-10-07T02:49:04",
        "timestamp": 1759776544,
        "message": "ComfyUI version 0.3.63",
        "author": "comfyanonymous",
        "email": "comfyanonymous@protonmail.com",
        "files_changed": 2,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "7326e46deeab97219cad32d0624991f9ffea4fe5",
        "short_hash": "7326e46d",
        "date": "2025-10-07T01:57:00",
        "timestamp": 1759773420,
        "message": "Update template to 0.1.93 (#10235)\n\n* Update template to 0.1.92\n\n* Update template to 0.1.93",
        "author": "ComfyUI Wiki",
        "email": "contact@comfyui-wiki.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "195e0b063950f585fe584c5ce7b0b689f8d20ff8",
        "short_hash": "195e0b06",
        "date": "2025-10-06T03:41:19",
        "timestamp": 1759693279,
        "message": "Remove useless code. (#10223)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 0,
        "deletions": 11,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "187f43696dd58f252075d2e3c6873706eb6b5fa1",
        "short_hash": "187f4369",
        "date": "2025-10-05T14:34:18",
        "timestamp": 1759646058,
        "message": "fix(api-nodes): disable \"std\" mode for Kling2.5-turbo (#10212)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 3,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "caf07331ff1b20f4104b9693ed244d6e22f80b5a",
        "short_hash": "caf07331",
        "date": "2025-10-05T10:05:05",
        "timestamp": 1759629905,
        "message": "Remove soundfile dependency. No more torchaudio load or save. (#10210)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 2,
        "additions": 1,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "b1fa1922df597af759150f4e26ecb276c9753ee4",
        "short_hash": "b1fa1922",
        "date": "2025-10-05T03:33:48",
        "timestamp": 1759606428,
        "message": "convert nodes_stable3d.py to V3 schema (#10204)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 89,
        "deletions": 66,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "2ed74f7ac78d3ff713d0a8583695c31055914b76",
        "short_hash": "2ed74f7a",
        "date": "2025-10-05T03:29:09",
        "timestamp": 1759606149,
        "message": "convert nodes_rodin.py to V3 schema (#10195)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 465,
        "deletions": 450,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "22f99fb97edaccf450152c8bf7c4068c1d331899",
        "short_hash": "22f99fb9",
        "date": "2025-10-05T03:22:57",
        "timestamp": 1759605777,
        "message": "fix(api-nodes): enable 2 more pylint rules, removed non needed code (#10192)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 3,
        "additions": 4,
        "deletions": 50,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "bbd683098e7d18700f025b2f0a4f6a44a3176602",
        "short_hash": "bbd68309",
        "date": "2025-10-04T11:37:43",
        "timestamp": 1759549063,
        "message": "Add instructions to install nightly AMD pytorch for windows. (#10190)\n\n* Add instructions to install nightly AMD pytorch for windows.\n\n* Update README.md",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 19,
        "deletions": 7,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "08726b64fe767f47bf074a05bedd6db45314c4c9",
        "short_hash": "08726b64",
        "date": "2025-10-04T06:22:43",
        "timestamp": 1759530163,
        "message": "Update amd nightly command in readme. (#10189)",
        "author": "comfyanonymous",
        "email": "121283862+comfyanonymous@users.noreply.github.com",
        "files_changed": 1,
        "additions": 2,
        "deletions": 2,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "93d859cfaaad150c2a1e5e54c8f14765fa79ecb5",
        "short_hash": "93d859cf",
        "date": "2025-10-04T05:32:19",
        "timestamp": 1759527139,
        "message": "Fix type annotation syntax in MotionEncoder_tc __init__ (#10186)\n\n## Summary\r\nFixed incorrect type hint syntax in `MotionEncoder_tc.__init__()` parameter list.\r\n\r\n## Changes\r\n- Line 647: Changed `num_heads=int` to `num_heads: int` \r\n- This corrects the parameter annotation from a default value assignment to proper type hint syntax\r\n\r\n## Details\r\nThe parameter was using assignment syntax (`=`) instead of type annotation syntax (`:`), which would incorrectly set the default value to the `int` class itself rather than annotating the expected type.",
        "author": "Finn-Hecker",
        "email": "Finn.Hecker3@gmail.com",
        "files_changed": 1,
        "additions": 1,
        "deletions": 1,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "4614ee09ca1aaca7ee8067d6c5c30695582326ff",
        "short_hash": "4614ee09",
        "date": "2025-10-04T04:24:42",
        "timestamp": 1759523082,
        "message": "convert nodes_edit_model.py to V3 schema (#10147)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 29,
        "deletions": 17,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "5c8e986e273d8af8b976fddbaed726e8278cf1fe",
        "short_hash": "5c8e986e",
        "date": "2025-10-04T02:50:38",
        "timestamp": 1759517438,
        "message": "convert nodes_tomesd.py to V3 schema (#10180)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 32,
        "deletions": 18,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "8c26d7bbe6663f589f0a9562921aafb3c48955c6",
        "short_hash": "8c26d7bb",
        "date": "2025-10-04T02:48:21",
        "timestamp": 1759517301,
        "message": "convert nodes_pixverse.py to V3 schema (#10177)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 1,
        "additions": 227,
        "deletions": 222,
        "languages": [],
        "changed_files": [],
        "analysis_level": "stats"
      },
      {
        "hash": "d7aa414141f02a456801704a3da323fa2ed8f5cc",
        "short_hash": "d7aa4141",
        "date": "2025-10-04T02:45:02",
        "timestamp": 1759517102,
        "message": "convert nodes_eps.py to V3 schema (#10172)",
        "author": "Alexander Piskun",
        "email": "13381981+bigcat88@users.noreply.github.com",
        "files_changed": 0,
        "additions": 0,
        "deletions": 0,
        "languages": [],
        "changed_files": [],
        "analysis_level": "basic"
      }
    ],
    "language_stats": {},
    "total_commits": 237,
    "branch": "f16219e3"
  },
  "scan_time": "2025-12-29T22:51:15.712778",
  "report_year": 2025
}